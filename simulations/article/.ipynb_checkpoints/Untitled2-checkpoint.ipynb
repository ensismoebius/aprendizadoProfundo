{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e50c44c6-6666-418a-81bb-ea4edb20da47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "import snntorch.functional as SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58616126-c7a6-4a1a-bdbb-3e883c159a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNNModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SNNModel, self).__init__()\n",
    "\n",
    "        beta = 0.9  # neuron decay rate \n",
    "        spike_grad = surrogate.fast_sigmoid() # fast sigmoid surrogate gradient\n",
    "\n",
    "\n",
    "        self.linearIn = nn.Linear(6, 10)\n",
    "        self.spike1 = snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True)\n",
    "        self.linearOut = nn.Linear(10, 27)\n",
    "        self.spike2 = snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True)\n",
    "\n",
    "        self.men = torch.zeros(1)\n",
    "        self.spk = torch.zeros(1)\n",
    "        self.steps = 4096;\n",
    "\n",
    "    def forward(self, x):\n",
    "        for step in range(self.steps):\n",
    "            self.spk = self.linearIn(x[step])\n",
    "            self.spk, self.men = self.spike1(self.spk, self.mem)\n",
    "            self.spk = self.linearOut()\n",
    "            self.spk, self.men = self.spike2(self.spk, self.mem)\n",
    "        return self.spk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e06d3f69-d04d-49f1-8b38-c9f9c1cb5a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SNNModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c8785a2-48f7-40bb-a65b-82250c630a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: torch.Size([4, 6, 4096])\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define the parameters\n",
    "batch_size = 4\n",
    "num_channels = 6\n",
    "sequence_length = 4096\n",
    "\n",
    "# Generate fake training data\n",
    "training_data = torch.randn((batch_size, num_channels, sequence_length))\n",
    "\n",
    "# Print the shape of the generated data\n",
    "print(\"Shape of training data:\", training_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9421f0b8-e40b-4645-bbb4-6fd290afe78b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'steps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m      7\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 8\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, target_data)\n\u001b[1;32m     10\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.venvTorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venvTorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[31], line 20\u001b[0m, in \u001b[0;36mSNNModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m---> 20\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinearIn(x[\u001b[43msteps\u001b[49m])\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspike1(x[step], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmem)\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinearOut()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'steps' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you have training_data and target_data\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3, betas=(0.9, 0.999))\n",
    "loss_fn = SF.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(training_data)\n",
    "    loss = criterion(output, target_data)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bc1d47-9f04-4f9b-b6ca-9a652e473a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
